# **ğŸ§  Competitive Code Reasoning with LoRA (Qwen2.5-Coder)**

Bu proje, **Qwen2.5-Coder-1.5B-Instruct** temel modeli Ã¼zerinde **LoRA (Low-Rank Adaptation)** tekniÄŸi kullanÄ±larak "Competitive Code Reasoning" (Zorlu Kodlama Problemleri) yeteneklerini geliÅŸtirmek amacÄ±yla yapÄ±lmÄ±ÅŸtÄ±r.

Model, iki farklÄ± veri seti (**DEEP** ve **DIVERSE**) ile ayrÄ± ayrÄ± eÄŸitilmiÅŸ ve performanslarÄ± karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.

## **ğŸš€ Modeller (Hugging Face)**

EÄŸitilen ve en iyi performansÄ± veren modeller Hugging Face'e yÃ¼klenmiÅŸtir:

| Model AdÄ± | Veri Seti | AÃ§Ä±klama | Link |
| :---- | :---- | :---- | :---- |
| **Qwen-Deep-LoRA** | DEEP Dataset | KarmaÅŸÄ±k akÄ±l yÃ¼rÃ¼tme gerektiren problemlerde uzman. | [Model Linki](https://huggingface.co/muzaffermut/Qwen2.5-Coder-1.5B-Deep-LoRA) |
| **Qwen-Diverse-LoRA** | DIVERSE Dataset | Ã‡eÅŸitli algoritma problemlerinde en iyi sonucu veren (Checkpoint-800). | [Model Linki](https://huggingface.co/muzaffermut/Qwen2.5-Coder-1.5B-Diverse-LoRA) |

## **ğŸ“‚ Proje YapÄ±sÄ±**

Lora\_Project/  
â”œâ”€â”€ scripts/               \# TÃ¼m Python kodlarÄ±  
â”‚   â”œâ”€â”€ train.py           \# LoRA eÄŸitim kodu  
â”‚   â”œâ”€â”€ evalconstant.py    \# Sabit seed ile model deÄŸerlendirme  
â”‚   â”œâ”€â”€ upload.py          \# Hugging Face yÃ¼kleme scripti  
â”‚   â””â”€â”€ download.py        \# Base model indirme  
â”œâ”€â”€ outputs/               \# EÄŸitim loglarÄ± ve model Ã§Ä±ktÄ±larÄ±  
â”œâ”€â”€ project\_report.md      \# DetaylÄ± proje raporu  
â””â”€â”€ README.md              \# Bu dosya

## **ğŸ› ï¸ Kurulum**

Projeyi yerel ortamda Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

1. **Repoyu klonlayÄ±n:**  
   git clone https://github.com/muzaffermut/Lora\_Project\_Competitive\_Code.git  
   cd Lora\_Project\_Competitive\_Code

2. **Gereksinimleri yÃ¼kleyin:**  
   pip install torch transformers peft datasets bitsandbytes accelerate

## **ğŸ’» KullanÄ±m**

### **1\. EÄŸitim (Training)**

Modeli eÄŸitmek iÃ§in aÅŸaÄŸÄ±daki komutu kullanabilirsiniz. DEEP veya DIVERSE veri setini seÃ§in.

python scripts/train.py \--dataset DEEP  
\# veya  
python scripts/train.py \--dataset DIVERSE

**EÄŸitim Parametreleri:**

* Epochs: 3  
* Batch Size: 1 (Gradient Accumulation: 16\)  
* Learning Rate: 2e-4  
* LoRA Rank: 16

### **2\. DeÄŸerlendirme (Evaluation)**

EÄŸitilen modeli test etmek iÃ§in:

python scripts/evalconstant.py \--dataset DIVERSE \--checkpoint outputs/diverse\_model\_checkpoints/checkpoint-800

## **ğŸ“Š SonuÃ§lar**

YapÄ±lan testlerde:

* **DEEP Veri Seti:** Final model (846. adÄ±m) en iyi sonucu vermiÅŸtir.  
* **DIVERSE Veri Seti:** 800\. adÄ±mdaki checkpoint, final modelden daha tutarlÄ± ve doÄŸru kod Ã¼retmiÅŸtir (Overfitting gÃ¶zlemlendiÄŸi iÃ§in 800 seÃ§ildi).

DetaylÄ± analiz iÃ§in project\_report.md dosyasÄ±na bakabilirsiniz.